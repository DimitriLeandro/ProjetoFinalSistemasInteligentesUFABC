{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCEPTRON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pacotes que serão usados para importação do *dataset*, separação dos dados em treinamento e teste, método de classificação *Perceptron* e as métricas para análise de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFININDO ALGUNS PARÂMETROS PARA PLOTAR GRÁFICOS\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "params = {'figure.figsize': [7, 4], \n",
    "          'axes.labelsize': 12,\n",
    "          'axes.titlesize':16, \n",
    "          'font.size': 12,\n",
    "          'legend.fontsize': 12, \n",
    "          'xtick.labelsize': 10, \n",
    "          'ytick.labelsize': 10\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação do dataset *Breast Cancer Wisconsin*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribuição dos dados de entrada a variável X e dos elementos *target* a variável y.\n",
    "\n",
    "Obs.: O elemento *target* do dataset é distribuído em valores 0 e 1, onde 0 representa o diagnóstico de câncer benigno e 1 o câncer maligno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimindo o formato de ambas variáveis geradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula abaixo contém a classe do Perceptron implementado pela equipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronImplementado:        \n",
    "    \n",
    "    def predizerDado(self, dado):        \n",
    "        # Tenho que ir somando cada dimensão do dado de entrada com o respectivo peso\n",
    "        soma = 0.0\n",
    "        \n",
    "        # Passando por cada dimensão e somando as multiplicações\n",
    "        for valorDadoDimensao, pesoDimensao in zip(dado, self.vetorPesos):\n",
    "            soma += valorDadoDimensao * pesoDimensao\n",
    "\n",
    "        # Retorna classe 1 se a soma der >= 0 e classe 0 caso contrário\n",
    "        if soma >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def calcularAcuracia(self, x, y):\n",
    "        \n",
    "        qtdAcertos = 0\n",
    "\n",
    "        # Passando por cada dado para predizer sua classe e comparar com a real\n",
    "        for dadoAtual, classeReal in zip(x, y):\n",
    "\n",
    "            # Fazendo a predição\n",
    "            classePredita = self.predizerDado(dadoAtual)\n",
    "\n",
    "            # Se acertei, então somo 1 em qtdAcertos\n",
    "            if classePredita == classeReal:\n",
    "                qtdAcertos += 1\n",
    "\n",
    "        # Retorno a porcentagem de acertos\n",
    "        return qtdAcertos / float(len(x))\n",
    "\n",
    "        \n",
    "    def treinarPesos(self, x, y, qtdMaxIteracoes = 10000, taxaAprendizagem = 0.5):\n",
    "        \n",
    "        # Irei alterar o valor dos pesos no máximo qtdMaxIteracoes vezes\n",
    "        for i in range(qtdMaxIteracoes):\n",
    "\n",
    "            # Primeiro calculo a acurácia atual para ver se já posso parar o algoritmo\n",
    "            acuraciaAtual = self.calcularAcuracia(x, y)\n",
    "\n",
    "            # Se já cheguei em 100%, então posso parar as iterações\n",
    "            if acuraciaAtual == 1:\n",
    "                break\n",
    "\n",
    "            # Senão, vou passar por cada dado para fazer a predição, calcular o erro e arrumar os pesos\n",
    "            for dadoAtual, classeReal in zip(x, y):\n",
    "\n",
    "                # Fazendo a predição e calculando o erro\n",
    "                classePredita = self.predizerDado(dadoAtual)\n",
    "                erro = classeReal - classePredita\n",
    "\n",
    "                # Se houve erro, então recalculo todos os pesos\n",
    "                if erro != 0:\n",
    "                    for index, pesoAtual in enumerate(self.vetorPesos):\n",
    "                        self.vetorPesos[index] = pesoAtual + taxaAprendizagem * erro * dadoAtual[index]\n",
    "    \n",
    "    \n",
    "    def treinarPerceptron(self, xTrain, yTrain, qtdMaxIteracoes = 10000, taxaAprendizagem = 0.5):\n",
    "        # Transformando tudo pra numpy (assim funciona com datasets reais)\n",
    "        xTrain = np.array(xTrain)\n",
    "        yTrain = np.array(yTrain)\n",
    "        \n",
    "        # A primeira coisa a fazer é colocar o bias no final de cada dado\n",
    "        for dadoAtual in xTrain:\n",
    "            np.append(dadoAtual, 1)\n",
    "        \n",
    "        # Começando com pesos aleatórios entre -1 e 1 e fazendo o treinamento\n",
    "        self.vetorPesos = []\n",
    "\n",
    "        # Pesos aleatórios para cada dimensão\n",
    "        for i in range(len(xTrain[0])):\n",
    "            self.vetorPesos.append(randint(-1000, 1000) / 1000)\n",
    "\n",
    "        # Treinando\n",
    "        self.treinarPesos(xTrain, yTrain, qtdMaxIteracoes, taxaAprendizagem)\n",
    "        \n",
    "    \n",
    "    def predizerDados(self, xTest):\n",
    "        # Transformando tudo pra numpy (assim funciona com datasets reais)\n",
    "        xTest = np.array(xTest)\n",
    "        \n",
    "        # Essa função faz a predição de n dados usando a função predizerDado (atenção no plural e singular)\n",
    "        yPred = []\n",
    "        \n",
    "        for dadoAtual in xTest:\n",
    "            # Tenho que colocar o bias no final\n",
    "            np.append(dadoAtual, 1)\n",
    "            yPred.append(self.predizerDado(dadoAtual))\n",
    "            \n",
    "        return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando K-Fold Cross Validation para analisar o algoritmo implementado e o do Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de fazer as comparações, é de extrema importância manter os parâmetros do algoritmo implementado e os do Sklearn iguais. A célula abaixo contém os parâmetros em comum dos dois códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os perceptrons\n",
    "taxaAprendizagem = 0.5\n",
    "maxIteracoes = 1000\n",
    "\n",
    "# Para o KFold\n",
    "qtdPacotesKFold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 1 finalizada\n"
     ]
    }
   ],
   "source": [
    "objPerceptronImplementado = PerceptronImplementado()\n",
    "objPerceptronSklearn = Perceptron(eta0=taxaAprendizagem, max_iter=maxIteracoes)\n",
    "\n",
    "#Instânciando um objeto KFold com 10 pacotes\n",
    "objKFold = KFold(n_splits = qtdPacotesKFold, shuffle=True)\n",
    "\n",
    "#Vetores de métricas para o algoritmo implementado\n",
    "vetorAcuraciasImplementado = []\n",
    "vetorF1Implementado = []\n",
    "vetorPrecisaoImplementado = []\n",
    "vetorRecallImplementado = []\n",
    "\n",
    "#Vetores de métricas para o algoritmo do sklearn\n",
    "vetorAcuraciasSklearn = []\n",
    "vetorF1Sklearn = []\n",
    "vetorPrecisaoSklearn = []\n",
    "vetorRecallSklearn = []\n",
    "\n",
    "#Rodando o Perceptron com o KFold\n",
    "i = 0\n",
    "for trainIndex, testIndex in objKFold.split(x):\n",
    "    \n",
    "    # Separando os dados de treinamento e teste\n",
    "    i += 1\n",
    "    xTrain, xTest, yTrain, yTest = x[trainIndex], x[testIndex], y[trainIndex], y[testIndex]\n",
    "    \n",
    "    # Treinando o perceptron implementado e o do sklearn\n",
    "    objPerceptronImplementado.treinarPerceptron(xTrain, yTrain, qtdMaxIteracoes=maxIteracoes)\n",
    "    objPerceptronSklearn.fit(xTrain, yTrain)\n",
    "    \n",
    "    # Predizendo os dados de teste\n",
    "    yPredImplementado = objPerceptronImplementado.predizerDados(xTest)\n",
    "    yPredSklearn = objPerceptronSklearn.predict(xTest)\n",
    "    \n",
    "    # Verificando métricas no algoritmo implementado\n",
    "    vetorAcuraciasImplementado.append(accuracy_score(yTest, yPredImplementado))\n",
    "    vetorF1Implementado.append(f1_score(yTest, yPredImplementado, average='binary'))\n",
    "    vetorPrecisaoImplementado.append(precision_score(yTest, yPredImplementado, average='binary'))\n",
    "    vetorRecallImplementado.append(recall_score(yTest, yPredImplementado, average='binary'))\n",
    "    \n",
    "    # Verificando metricas no Sklearn\n",
    "    vetorAcuraciasSklearn.append(accuracy_score(yTest, yPredSklearn))\n",
    "    vetorF1Sklearn.append(f1_score(yTest, yPredSklearn, average='binary'))\n",
    "    vetorPrecisaoSklearn.append(precision_score(yTest, yPredSklearn, average='binary'))\n",
    "    vetorRecallSklearn.append(recall_score(yTest, yPredSklearn, average='binary'))\n",
    "    \n",
    "    print(\"Iteração\", i, \"finalizada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando as Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorAcuraciasImplementado, label=\"Algoritmo implementado\")\n",
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorAcuraciasSklearn, label=\"Sklearn\")\n",
    "plt.title(\"Comparação entre as acurácias dos algoritmos\")\n",
    "plt.xlim(1,qtdPacotesKFold)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Acurácia média do algoritmo implementado:\", np.mean(vetorAcuraciasImplementado))\n",
    "print(\"Acurácia média do Perceptron do Sklearn:\", np.mean(vetorAcuraciasSklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorF1Implementado, label=\"Algoritmo implementado\")\n",
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorF1Sklearn, label=\"Sklearn\")\n",
    "plt.title(\"Comparação entre os F1 scores médios dos algoritmos\")\n",
    "plt.xlim(1,qtdPacotesKFold)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Média do F1 score médio do algoritmo implementado:\", np.mean(vetorF1Implementado))\n",
    "print(\"Média do F1 score médio do Perceptron do Sklearn:\", np.mean(vetorF1Sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorPrecisaoImplementado, label=\"Algoritmo implementado\")\n",
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorPrecisaoSklearn, label=\"Sklearn\")\n",
    "plt.title(\"Comparação entre a precisão média dos algoritmos\")\n",
    "plt.xlim(1,qtdPacotesKFold)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Média da precisão média do algoritmo implementado:\", np.mean(vetorPrecisaoImplementado))\n",
    "print(\"Média da precisão média do Sklearn:\", np.mean(vetorPrecisaoSklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorRecallImplementado, label=\"Algoritmo implementado\")\n",
    "plt.plot(range(1, qtdPacotesKFold + 1), vetorRecallSklearn, label=\"Sklearn\")\n",
    "plt.title(\"Comparação entre o recall médio dos algoritmos\")\n",
    "plt.xlim(1,qtdPacotesKFold)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Média do recall médio do algoritmo implementado:\", np.mean(vetorRecallImplementado))\n",
    "print(\"Média do recall médio do Sklearn:\", np.mean(vetorRecallSklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
